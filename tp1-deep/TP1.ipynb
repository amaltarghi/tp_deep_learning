{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-learning TP1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce TP1 est d'acquérir les bases nécessaires à la compréhension des réseaux de neurones à partir d'un modèle simple de type Softmax. La tâche d'apprentissage consiste à classifier les images (28 par 28 pixels) de la base MNIST (http://yann.lecun.com/exdb/mnist/) en 10 catégories représentant les chiffres 0-9.\n",
    "\n",
    "Le TP2 consistera à généraliser les concepts de ce TP1 à un réseau de neurones multi-couches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement de la base d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download mnist data\n",
      "--2016-11-30 10:59:53--  http://deeplearning.net/data/mnist/mnist.pkl.gz\n",
      "Résolution de deeplearning.net (deeplearning.net)… 132.204.26.28\n",
      "Connexion à deeplearning.net (deeplearning.net)|132.204.26.28|:80… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 16168813 (15M) [application/x-gzip]\n",
      "Enregistre : «mnist.pkl.gz»\n",
      "\n",
      "mnist.pkl.gz        100%[===================>]  15,42M  1,98MB/s    in 8,0s    \n",
      "\n",
      "2016-11-30 11:00:01 (1,94 MB/s) - «mnist.pkl.gz» enregistré [16168813/16168813]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if(\"mnist.pkl.gz\" not in os.listdir(\".\")):\n",
    "    print('download mnist data')\n",
    "    !wget http://deeplearning.net/data/mnist/mnist.pkl.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de la base en mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32),\n",
       " array([6, 3, 5, ..., 5, 3, 1])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataset_loader\n",
    "train_set, valid_set, test_set = dataset_loader.load_mnist()\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez visualiser les différents caractères en changeant l'identifiant de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJztnW1sZGl15/+n7Xpxu3s8vKx6VsuKQCZIg6KgbbOws2TC\n7A4SCSsN+UTkgBCbDwgRImRpFYSEdmbhQxQQaXYhs0IrLQQRLI3EElg00BBEXkYbmKgdEl6GIMjw\nOkwHGMndbbtsl/3sh6qnOHV8nvtSrvKte/3/SVd1q1yuukV5fpw+z3nOkRACCCGEVMO5qi+AEELO\nMpQwIYRUCCVMCCEVQgkTQkiFUMKEEFIhlDAhhFQIJUwIIRVCCRNCSIVQwoQQUiGLVV+AiDwLwCsB\nfBdAr9qrIYSQqdAF8AsAroYQfpb1xJlJWER+F8B/AXAHgL8H8HshhL91nvpKAH86q+sghJAKeS2A\nj2U9YSYSFpHfAvBeAG8E8BiAdQBXReQFIYSfmqd/FwA++tGP4q677hr7wfr6Oq5cuTKLS6ycJn82\noNmfj5+tvpzW53v88cfxute9Dhj6LYtZRcLrAD4YQvgIAIjImwD8JwC/A+Dd5rk9ALjrrrtw+fLl\nsR+srKwce6wpNPmzAc3+fPxs9aWCz5ebYp36wpyItACsAvhCfCwMWrX9OYC7p/1+hBBSZ2ZRHfFs\nAAsArpvHr2OQHyaEEDKEJWqEEFIhs8gJ/xTAIYBL5vFLAJ5K/dL6+jpWVlbGHnvuc5879YubF9bW\n1qq+hJnS5M/Hz1ZfZvH5NjY2sLGxMfbY1tZW4d+XWUzWEJEvAfhyCOGtw/sC4PsA/kcI4T3muZcB\nXLt27VqjFwQIIWeHzc1NrK6uAsBqCGEz67mzqo74IwAfFpFr+HmJ2nkAH57R+xFCSC2ZiYRDCA+L\nyLMBvBODNMRXALwyhPCTWbwfIYTUlZntmAshPATgoVm9PiGENAFWRxBCSIVQwoQQUiGUMCGEVAgl\nTAghFUIJE0JIhVDChBBSIZQwIYRUCCVMCCEVQgkTQkiFUMKEEFIhlDAhhFQIJUwIIRVCCRNCSIVQ\nwoQQUiGUMCGEVAglTAghFUIJE0JIhVDChBBSIZQwIYRUCCVMCCEVQgkTQkiFUMKEEFIhlDAhhFQI\nJUwIIRVCCRNCSIVQwoQQUiGUMCGEVMhi1RdASN0IIZS+zXssnotI4UNj71vyfk6qgxImZAJCCDg6\nOhq7zXpMH/Yx/fyFhQWcO3cOCwsLoyN1X4s1nnuPkfmGEiZkArREDw8PM88PDw8LHSEELC4uotVq\nodVqjc69xwCMRcTxPIRw7JzMN5QwISXREe7h4SH6/f4xoerH+v0++v0+Dg4ORufecXR0hHa7jXa7\njU6nc+w83gLZaYsIBVwPKGFCJkBL+PDwMFOw+/v7ODg4GB2p+4eHh1haWkK32x07Dg4O0O12R3nj\nc+fOYXFx8Zh8z53z19kp4/mGEiZkAmwkHCNde+zv74+Ovb29sVt73u/3cf78+bEjylmnGRYWFtBq\ntUbijbdHR0djMqZ86wElTEhJbBQcBayFG6Pbvb097O3todfr5d72+31cuHABy8vL2NvbGwn46OgI\nAEYLcu12G4eHh8dkG+/rqguKeP6hhAmZABsJawlH8cZjd3cXvV4Pu7u7yfNer4eDgwPs7u4mBRwX\n5XR0HEIYS0OcO3eO8q0ZlDAhE+BJOEa+Orrt9XrY2dkZHbu7u8n78fdjflnngGME3Ol0Rot4llgR\nYQ8Keb6hhAkpiVcdERfgvOh3e3s789jZ2cH29vbYAl2UZ4yA2+02ut0ulpaWRpUXUdLAQMBRzFHG\npB5QwoRMgK4FtumIGAHHKHd7exu3bt3CzZs3cevWreSxt7c3FuXqRbhOp4OlpaWxVIVG1wvrKJjM\nP5QwIRPgLc7ptESMirWQ9RFTEDoi3tvbGytNW1paGvudmOaIFRVxB53ebRfRMibzDSVMSElszwcd\nFadK1uyGDr1l2R5ZEXYUeLfbHdtRd3h4iMXFRSwuDv6TzqsdJvMDJUzIBHi9IjwRx8PuqPMkDIyn\nObyoWkfSrVYL/X5/tKXZNgGKlRJkvqGECZkQG7l6ArY76bSAtYj163n1x7baQm9p1q8BYCTghYUF\nSrgGUMKETIBNH3gi9gRsG/bYSDiVjtCRcOwhYSNqYFzAVs5kPqGECZkQr02lTUNoEdtUhBUogGOv\noyUcS9/a7fYoD5yKgBcXFynhmjD1rL2IPCAiR+b4xrTfh5AqKRIJ2yjYE3HRhTlv84eumog1xvY9\nKOH5Z1aR8NcA3AcgbtXpz+h9CDl1igo4VR1ho2CbjsjKCcdqCJ3vtRFwq9Vyo2wyn8xKwv0Qwk9m\n9NqEzAXe5Iy8HsI2SrULc94mkLidWQtYd0+L8o0C1guAlPD8MysJ/5KI/AhAD8DfAHh7COEHM3ov\nQk4dr0StqICzStRS6YhWq4VerzcmYC8C1lE3N2vUg1lI+EsA3gDgHwH8SwAPAvgrEfnlEML2DN6P\nkEoompLwomAdqXoCthKOEbCWsJZvq9Uaa/DDSLg+TF3CIYSr6u7XROQxAN8D8BoAH5r2+xEyDcrI\nyktB6MU3r7l7VoWEjViLbIleXFwcm9CRWvQj88/MS9RCCFsi8i0Ad2Y9b319HSsrK2OPra2tYW1t\nbZaXR8gxrBDtuY1UU1M0YjWDnp5hhexJ2BtbpA87eTkeqVlzZLZsbGxgY2Nj7LGtra3Cvz9zCYvI\nBQwE/JGs5125cgWXL1+e9eUQkolND9jbWL2gI1+vqbtt7u5FrToa9siTsXdQxKePFyxubm5idXW1\n0O/Pok74PSLyayLyXBH59wA+AeAAwEbOrxJSKVbA3maMvEY9drpGrOHVc+S8Kgnb96FIFGyjYT1z\njgKuD7OIhJ8D4GMAngXgJwAeBfDvQgg/m8F7ETJ1UhsovN4ONlfrjTfy8sN5GyqKyNhGwFbAlHE9\nmMXCHJO4pLakxGsl7KUjrIhjPjiK1y7SpRbmmBM+W7B3BCFDbCrC1gGnSshSC3N6irLdylxka3HZ\nnDAlXE8oYUIUqShYR612tpw3UUOLWEvb27Bhu6DliTcVBXvpCDL/UMKEKLy+EEUX5rxIOEpY/15q\ns4YmJeMo36ILcxTx/EMJEwIck2GWjLM2Z3h1wnb6RqqBj11Q0wL2RMyURDOghAlRpKoi8tpV2nSE\nPrwUh3dYcRZZnKOA6w8lTMgQT8BWvCn5po79/f2x147n9jFNXkVE7JhmUxK2uQ9lXA8oYUKGeHXA\n3q3O/dpOaanZcfo97GMam3bwGvToo91uj35um/xw0nI9oIQJGeJFv3ZCRr/fH9uGrDul5fUKLoKV\nsCfidruNbrc7JuEYHdt+w4yE5x9KmBCMR6ipWuB4ntWQx+sVbN/Dw6YQbOphcXFxbMKyjoS1iG21\nBCU8/1DChAzxJltk9YdIbUO2mzCsfPNknEpH6JREt9sdEzDTEfWFEiZkiLcgl9qS7InYa09ZVsBZ\n6YgikTDTEfWDEiYEaQGnNmOkBOw1Vc8Tr9c3wqYjYrRrF+Y6nc4xAVPC9YL/XiFkiBaxtytO1wDn\npSRSkbCHrQ0uEgnbhTktYls7TOYbRsKEDLECtnPerIhtJOyVqKXqgL3HvHSElxOOIo73UzlhCrge\nUMKEwN+mnNWcp2h1ROq9gGwZe6PsbSQcH9e3Xj8JMt9QwoQMyaoT9hbmdMWE7Y7mpSPyhGgFnLcw\nZ2uDbTqCOeF6QAkTMqRITtjmgr3KiEmmHUdZ2q3KdmFOSzj+PDXyiAKuB5QwIYpU74hUH4lURzSL\nbS3p3do2lamZckUnazASrgeUMCGKok18PAEXEbE3A05HwSn5Zgk51c6S1ANKmJAhduuy1wc4tTMu\nS8CpCNXbqmxFnJKvLUVjO8v6QgkTAn++XErARVIRRWWsxVkk/ZAVAbM+uJ5QwoQMKSNgK+GitcEp\n+epdcnlRsF1886Jg/V5kvqGECTHkjTay6QhvYoam6Nii1By5lIzta3BRrp5QwoQobF7Yq5KYVMSp\nKNgbWVQkHeG9HgVcPyhhQoYUnS2Xl5LIIjUzLmuSsl2QsxJOVVxQxvWAEibEkEpF2Cg4FQGndst5\n6YgyAk5FwvH1vVsy/1DChAzxJFq0OiKvRC3eZuWDbcVDloAXFxfd9/DuU8jzDSVMGo2NRlP3bWlZ\nKgJOiXiSWuFJc8HxIM2AEiaNJW+qhb3vNe+xjXt6vR56vd5YX2HdxMcrVfOEaxvvLCwsuH2COS2j\n+VDChOB48x6vhaWWcK/XS7az1At0dkec7oqmm/MsLi4mR9nbumBKuFlQwuTMY3PAk0TCqckagD+8\nM05P1g3b7QDPdrt9LBLmbrjmQQmTM0tWOsI2dLeRsBawFbFtY6m3JHutKaOMYyrCG1ukKyJIs6CE\nyZnD21acl47Y398/loooEwlbEdv+wO12G91u180J214RFHGzoITJmaKIgL10hI2EvSjYzpiL2OY8\nqUkZS0tLmZEwc8LNhBImZ4aUgPW5N1/OywnryRp2xJGOhL1yNJ2SiNKNUXCRnDBpFpQwObOkBBxl\nqgVrI+EoaD1pOSsn7FVH2Eg4KyfMhu3NhRImZ4KsGmGvOiIVCUcR6xxwPLclal51RGpmnI6EUzlh\nnZIgzYESJmcOK+B4m1cn3Ov1sLu7i93d3WQ3tax0hBcJ6yg4Kycco2FGws2DEiZnCk/AkawdczYd\nkRp/5DV293LCNh3BnPDZhRImjcYbOeR1OtPbj1N53qLDPbOma+jcblajntTcuPg6pDlQwqTReD2C\nvfOsaoe86cplO6ilpml4EzVSIibNgRImjcVOyfAkGg8tXy8S9rqmeRG1PQeyBVwmCqaAmwklTBqN\n1xPYO9ebLmxDniJtK20UnEpH5E3WsDvj7GIcRdw8KGHSaGzVQ6o3cFYkbHfC5U3TKCLgMjlhRsTN\nhhImjcWbkKHrefW5tzCX18Q9teBnSU3WSE1WpnzPFqXrXUTkHhH5lIj8SESOROR+5znvFJEnRWRH\nRD4vIndO53IJKYddQLPlZ7oe2IuGrYBtHXCqOsJSJA1RNBImzWKSosNlAF8B8GYAx/7aRORtAN4C\n4I0AXgJgG8BVEWmf4DoJmRhvS7LdEZeViigzVy4l4qLVEToyTkXCFHGzKJ2OCCF8FsBnAUD8v4a3\nAnhXCOHTw+e8HsB1AL8J4OHJL5WQ8qQ6pHm74rIi4ayx9nljk+zQzZPUCVPAzWOq229E5HkA7gDw\nhfhYCOEGgC8DuHua70VIHl5OWHdIK5KK8ERsXzMvJwykI2Ev+vUOyre5THth7g4MUhTXzePXhz8j\n5FTxStRsFKyb9NiURGphbhLK5IVtFMy+Ec2F1RGk0dgewVa6uidEnJRhc8TetAwPT5BZmzNSY450\nv4iUlElzmLaEnwIgAC5hPBq+BODvsn5xfX0dKysrY4+tra1hbW1typdIzgqp9pS2SXtqgGdqgrIl\nJd94a7uo2cbuumFPqnsaBTy/bGxsYGNjY+yxra2twr8/VQmHEJ4QkacA3AfgHwBARG4D8FIAf5z1\nu1euXMHly5eneTmEJBu120kZu7u7xwZ4pqZlaOyim/2Zl/+1o+7trDnbPY2R8HzjBYubm5tYXV0t\n9PulJSwiywDuxCDiBYDni8iLADwdQvgBgPcBeIeIfBvAdwG8C8APAXyy7HsRchLyGrXrVIQnYZsX\nLpqKyNuckRUJxyjYpiW4QNdcJomEXwzgixgswAUA7x0+/icAfieE8G4ROQ/ggwBuB/DXAH4jhLA/\nheslpBReo/YsAdu8cGpaBjAuW+82nmcJ2OaEU6Pu47h7RsLNY5I64b9ETmlbCOFBAA9OdkmETAdv\nu7IVsZ6WoUVsI2ErYEuWkItGwp1O51gU7EXClHCzYHUEaTR2o0ZeTjiOs4+R8CQ5Ybu7rUwkrB9P\n5YRJs6CESWOJ0vTGFe3v748JOLUwl6qOSC3IWQFnRcJeZYSOgLMW50hzoIRJY8lKR9icsJcX9tIR\neTvi7P2sSNibuhx/zhrhswMlTBpNamHO5oR1nXDWZg2NJ0W7PTkvErbRsNfIhyJuNpQwaSxFStSy\n6oS9Dmp5DdvLCNgTse0f4TXzIc2CEia1IqtCwXtuarOGt3XZ27Icp2rYVITt6ZC61Rswomxt9YPN\n+8ZyNPYUPhtQwqQReHL2Grl7LSzzBJyqEU5Fq/p+p9MZO3RFRKvVOta4x0bPFG7zoYRJrckarplq\n5m4jYS3iVC9h3aoy1Q/COzqdDrrd7lhE7DXqscM9vT7CFHIzoYRJbfGmWOhzK2CbF86LhL0+whEb\nCWuh6jSDlnAUsbctWU/S8CYte7vxSDOghEktSY0TskL2mrmnIuG8yRpeTjirKc/i4uIxAXtRsI6G\nvf7BjISbDSVMakueiFPN3FORsNfQ3ZueYfO2Xs1vPO92u0kR611xWSkIrwyONAdKmNQOL/2QNYI+\nJWBbIaGfk9dL2OaEUzvg8gTspSO8FASj4eZCCZNaYkWcEnDelGUdCdsqiiILczonbHe/RQnbhbm8\nVpWpHhQUcDOhhElt8aohigg4NeYoPte7LZoT1h3ROp0OlpaWxkrUbF7Y7pDLa49JETcPSpjUGive\nIiL2BLy/v39srL2tEY4SLpITjlURqUhYL95pEWuYCz4bUMKkEWQJOG9hLh52nL13rkWcygnHqNdK\nOFWipufIkbMHJUxqR54o47mWrt0xZ3O//X4/N6pObVvO6hWckm6qNpicPShhUiuyol2dOjg6OnJL\nzrxcb97UjBRFROz1iGAvCKKhhEktsakG79zbfJGq/wXS+WWL1yEta6S9FTBbUxINJUxqh21Rabcm\n245pNhLWZWc23+uJN0/GWqyppu1Z4+sp4rMNJUxqRarywUo2Lr55my9S9b9eVJwiq1+w7RlsKyBs\n1zVytqGESe3QEWyqQY+ugPBywl75WWr3nX7fiNdPODW+KJUTZjqCAJQwqSF5NcBRul5/4DwRx9f3\nbi1eXjhPwF7vYIr4bEMJk1ph0xE6J+xFwakKiVQ6Qr+PvrVkpSKyFuYYCRMLJUxqiZcTTgk4NS8u\nlY7Q7+Gd234OedOUbctK26yHnG0oYVI78nLCWsKpxbmsfLD3fpa8ErWFhYXk9uTU7DhyNqGESa0o\n2qAnLx+cqhXW75NFVq1wKi/MOmHiQQmT2pEVAXtz4/b395MLc1mbMvLIygnrYZ521xx3zBENJUxq\nhY2Cvf7AvV5vNMY+a35cKgrOe3/geCTs1Qd7Is7asEHOJqwUJ7XDpiHsqKK9vT30er2RjLWEvWi4\nKFbWNrfrNfCxIvY2bFDAZxtKmNQKW56WmhmnJayHeMbnZ+WDU++rSUXC3pQNr0LCCpgiPrtQwqR2\n2JywTkdoAReJhCcRMJC/UaNoOoKRMKGESa0okhPe29vD7u7uWCRspykXzQmnBBxvs/pGFElHMB9M\nKGFSO06SEz44OCicEy7TwMfbqBHHGaWqI7gwRwBKmNSMVE5YR8E6HdHr9ZKVEVmRcJE0RVYbSy8K\nZjqCeFDCpHakcsJZC3NZ6Qjv9fMoujBXNB1BEZ9dWCdMaoWXEz5JiVqqcU8eRXfLeekIzpYjGkqY\n1A6vcY/drFGmRC1SdtdcamEuLxXBhTmiYTqC1ApvwKfXuEdvX/Z6SEyyWy7iNXTPameZSkOwTpgA\njIRJTUlNWk6NM/KmMXtj7Itg88E2LWEX61LVEMwHE4ASJjVEt5205Wp6sc7OnksJOK8UzXtMC1UL\n1so4dVC8JEIJk1rhDebMamnpNXIvMtI+6zFPvlnRcF4UTCGfbShhUku8dEQqGi7aQxg4LlvvZ1ag\nRSNfjrknHpQwqR2pKNgbdZTXQziVE/YWzDwJ58k3NUnDVkZQyGeX0tURInKPiHxKRH4kIkcicr/5\n+YeGj+vjkeldMiHZEzZsFJyasJzCitFLH3gpBqYjyCRMUqK2DOArAN4MILWi8RkAlwDcMTzWJro6\nQgyefD0BezPl8iYsA76A423q4MIcOQml0xEhhM8C+CwASPovaS+E8JOTXBghKcqIOG/CciQr7WDP\nrXDzStRSkTOjYALMbrPGvSJyXUS+KSIPicgzZ/Q+5IyiRawFm8oHFx1zH/GqIfR52YW51OKcfS9y\n9pjFwtxnAHwcwBMAfhHAHwB4RETuDpNsTyLEkBcFe3XCqXSExkamXsSqxVs0Gk5VRjASJsAMJBxC\neFjd/bqIfBXAdwDcC+CL034/cjbJqhe2FRNF64MjVrT28HbDeVUQRVIQlDGZeYlaCOEJEfkpgDuR\nIeH19XWsrKyMPba2toa1Na7pkdPBi3C9iDc2a49Hql9w1mIexdscNjY2sLGxMfbY1tZW4d+fuYRF\n5DkAngXgx1nPu3LlCi5fvjzryyHExYt0U9Fup9NBp9Mp3LCd8m02XrC4ubmJ1dXVQr9fWsIisoxB\nVBv/kp4vIi8C8PTweACDnPBTw+f9IYBvAbha9r0IOU10xGs7oumj0+mMRcFlImH9XpQxASaLhF+M\nQVohDI/3Dh//Ewxqh38FwOsB3A7gSQzk+19DCAcnvlpCZojOBet2lLotpSfhVCSctbCn35OcbSap\nE/5LZJe2/frkl0NINXjlZnYihp6WoaPgIiLW7xHPCQHYO4KQEalIWIu21WpNlI6Ir591S84mlDAh\nQ2xO2EbAMQqeZGEuvr5+L0IASpiQMeyinBWwd2RFwufOjWfurHwpY0IJE4L0CPtUFOylI1KRcOr9\nCAEoYUJGZKUjdOQbJWxzxamcMCFZUMKkcsq0FLFbjvWcOO+8DLZCIisS9kRcJhImJEIJk7nEk6ge\n0pnqEWHHGXnN3L0+EjqHq+Wro99ut4ulpSUsLS0dE7HOCVO+pAyUMJkrvAnI+twTqtesx4q5SBMf\nLxURS9KihO1hRWxrhAnJgxImc4MVsDeW3uuWlmpnWaSLmm3srhflvDREjIStgG1KggImRaGEyVyQ\nldstIuAsKWelIiK2MsIuyNl0hJZwu9120xEUMSkCJUzmBk+6RXoGp468PLBFL8p5C3IxBaElbDdt\nMB1ByjKr8UaEnAhPwFkLcikxawF7Io4yTkXCVsJRwDYS1otzFDApAyNhMhdkSTcrEs5LP6Qi4vie\nGtvG0ssJ20jYLsrZOmFC8qCESeXYSghPwF5pWl6ZWtnxRifJCdt0BAVMisJ0BJkbUrngsgLOSlWk\nUhLeluVUTlinI5gTJieFkTCZK/JEXETG3nTlrHxwxC7MeRs29GYNvZWZ1RFkUihhMhek8r7eYlzR\nw0a+qfI0oPjCXLy1XdRarRajYDIRlDCpnCjIfr9/TKT2sRs3buDWrVvY3t7Gzs4Odnd3sbe3h729\nPRwcHKDf7+emHlK78bw2k/ZIjS2yzyekKJQwqZwQwkiyUaSp25s3b+LmzZu4devWSMK9Xg/7+/uj\n5+g0REq8WYtzeUeRKcoUMSkKJUwqR0fCBwcHODg4wP7+/tgRH4sC1pFwr9cbi4QPDw+TEbAn3izK\niDg+n5AyUMKkcqKEYyQc0wvekZKwlrXOB8fXLyPiLPHmTVL2bgnJghImlRPTETES3t/fx97e3kiw\nvV5vdH7r1i3cvHnzWE44Kx0R38NLSVi8lEKRFAXzwWRSKGFSOTod0e/3sb+/P5Lvzs7OSLY7Ozu4\ndevW6MhKR2RJOLUwFymaD/YmKuvXIKQIlDCpHF1+ZiPhnZ0dbG9vjx06HRFlHdMRWRL2bjVFo+BU\nSoLRMJkESphUjk1H7O3tjVIQNvqN8tURsi1RiwtzMScc38OeZ0XB+jyvIoLSJSeBEiaVY6sjvEj4\n1q1buHHjxki8+sgqUdPvYd8zizIRsH0+IWWghEnl2DrhmBPe3d0dpSBu3rw5knDMAcdURLzvpSP0\ne0zCJHXCFDEpAyVMKicvEo4VETdu3BhLP8Tn6eoIXaI2iXjzotyidcIUMSkKJUxmRlEJ2p4Reruy\nt4Ejph3slma7GBfJq+MVkWN9IPSh+0jo+96Ye6YkSFkoYTITykahXoOeKNpYtqYlrEXs9YqIFK3t\n9eTrydgb6qklnFW2RogHJUwqxWtZqSUchWuPVCRsRWzTB6lb3RUtFRFnRcG6hSW7qJEyUMLk1PEq\nFbyWlVG0Nh2hG/qk6oKBcQHnHUUiYX3o5u9eJExIUShhcqp4aYq8nLBesNPy1ZFwXjpCz4/zbm0E\n7EXDOgr2XiOrzSUhKShhcmqkBBxvUzlhLxVhew2nJAz4IrZHlny9fLCOfFM5YUKKQAmTU6GIgL1o\n2EtHZE3SyIuC49QMe5sXBVsZ280bXJQjk0IJk5mTt1vNS0dkRcPeYE9vlpy3202LWB9FomB9m9fQ\nB2CtMCkGJUxOlZSAPQmnIuGsYZ9FcsJ2hpyOhIvmhbN2yzESJmWghElleP19o0xTAj44ODiWvvAG\neQLFBKyPImmIeMTXj3DHHJkUSpjMlFT/BnuemqbspSPKji4qIuMiOWGdviBkWvCvicyMLFnqI/Z+\n8HbD2eoHb2SRfc9IFG8UbqvVQqfTGY2w1+fLy8tYXl7G+fPn0e12R2Pt7e441gGTaUMJk5ngVTzY\n+/Hca8JjBVxmVJE+jxKOEW6UbxRtPJaXl3HhwoUxEUdJ67I0QqYNJUxmQhSjV8lgb/VkDK9Bj110\nS8nY4kXC7XYb3W4X58+fx9LS0uiIEo6PawnHSJhRMJkFlDCZGak8r91oYSPh1I44T8LebURLWEfC\n3W4XS0tLOH/+PM6fPz9KRcRDSzjmgxcWFlj1QGYCJUxmQqohj3fopuy2L/CkAgZ+LuG4mBYlrKNf\nnYaIqQibjmAkTGZJqSSXiLxdRB4TkRsicl1EPiEiL3Ce904ReVJEdkTk8yJy5/QumdQBr+TMlpvF\n6RgxEo5z4sqkI7z31XgLczoSvnDhAi5cuICLFy+OZBwjYbswx5wwmQVl/6ruAfB+AC8F8AoALQCf\nE5Gl+AQReRuAtwB4I4CXANgGcFVE2lO5YlIbvM0XenKGHlFkI2EtYLsluWheOCsdodMQFy9eHEnY\nywnrhTlorNrAAAAPiUlEQVRGwmTalEpHhBBepe+LyBsA/DOAVQCPDh9+K4B3hRA+PXzO6wFcB/Cb\nAB4+4fWSmmDTEanNF6kRRak2lWWi4FSJmo2Eo4B11YQuYWM6gsySk/776nYAAcDTACAizwNwB4Av\nxCeEEG4A+DKAu0/4XqRGZElYpyLikZqckZWOsO/lYSPhWB2hKyJ0JBzTEUtLS8cW5ihhMgsmXpiT\nwV/j+wA8GkL4xvDhOzCQ8nXz9OvDn5EzhE1HeDlhfXjpiLw2lVnYSNirjtCRcGoLM3PCZJacpDri\nIQAvBPCyKV0LaRB5vSB0TjhvYe7w8LC0gIHj1RE6HWFzwhcuXDjWWc22vGQkTGbBRBIWkQ8AeBWA\ne0IIP1Y/egqAALiE8Wj4EoC/y3rN9fV1rKysjD22traGtbW1SS6RzIAyEtSpCB0B6zTEzs7OaKz9\n7u7u2AKdN8hTk9U8J57bVpXeoefKaeF6o4soYOKxsbGBjY2Nsce2trYK/35pCQ8F/GoALw8hfF//\nLITwhIg8BeA+AP8wfP5tGFRT/HHW6165cgWXL18ueznklCgbheblgqN8d3Z2sL29PZKwzg+n5sel\nJibbnxUZY58aXZ/qE0wRE4sXLG5ubmJ1dbXQ75eSsIg8BGANwP0AtkXk0vBHWyGE3vD8fQDeISLf\nBvBdAO8C8EMAnyzzXqReeItlWsRawlbA8dxGwnrDRqpHcGqash5jb/O7uo+wF/lycCc5TcpGwm/C\nYOHtL8zj/xnARwAghPBuETkP4IMYVE/8NYDfCCHsn+xSyTySipCzJKwj4Sjh3d1d7O7ujuWGvXSE\nJ93UYaNgK1+d87Vz4zi4k5wWZeuECy0PhxAeBPDgBNdD5hQRKTSmKGIFXETCdtNGXjoiNfE4nhdJ\nQ6RSERzcSU4L9o4ghSgjYK9G2O6S0xKOUbDOCafSETr3mzU9eWFhoXROOCsCpojJrKCEyYnxevna\nqckxEo6i1XlhLWCbjtB1whGbhkhNUS4SBXsN21MTlON7EzJNKGFSGk+6XiRcpDoiRsLxZ3rnnM4J\npxbmvOnJ3hh7XaaWygnb6cxe5QUh04YSJoUokhPWj+XVCWsJ6xREarpGFLutiEiJOG9gpxcJc3oy\nqQJKmBQiq07Y6+1ru6fZ9pVawjr9oAUcc8J56QgrYrsRIyVgLe4o4fj63vRkipjMAkqYlCKvqboV\nsZeOiAtxWsJ62oa+zUpHiEjuGPuimzS0hON7aChgMisoYTI1bI9fnRu2kzV0ikJXQejDdk4LIYyl\nIuzI+njEFpSxL7DuDaz7A9uqCAvFS04DSpgUwssJR1K5YXvoqcuedO1oe69zmtcj2E5Rjud2UobX\npJ074kjVUMKkEEWaqNvHrIB1rliXr2kBpyJgTUrCOvKN/YL1pAxvZFEq10sxk9OCEiZTIdVoXQs1\nKxK2EbCNgvVmDW9ahu0T7EnYRsKpHsEUMDlNKGEydWw07Am2jIS9RTkbCcdI146xj/fjpAxPwqwD\nJlVCCZNC6Jywt1nDO8/KB1sR63SFF0Xr68hKR3ij7PMiYZafkSqhhEkhivYTzhOxJ+C4GSMlYCti\nXRfsTVGOY4uKpiMoYFIllDA5MXnVEVmpiLgw51VTeItyWZGwHeAZBcwR9mSeoYTJROR1UYu3RWVs\nF+G81wDSEo4CjgtzMSVhx9hHCdumPUWhtMm0oYTJTLAS1TlfLy2R1RTIywnHzRpeOkJHwrFyQm/i\nOEk6Im4YIWRaUMJkYvIa+hSJgOOReg2PWB3hbdSwErY9JIqUqHnvF+VbNDdOSFEoYTJTUuOIbBN1\nTZbcvSbuqa3LnU7H7R1hUxFFqiNYxkZmBSVMJsZGhvp+VqtJ3eWs2+3i4OAAwPH8r3eemqbhdUaz\nDXo4sojMI5QwmQmpxus6Yo3R6rlz59wtzt7CnpVqSsbe6CJvegZFTKqGEiYTkRcF256/tuG6lbDd\nrKF3zcXzrLFGWUdWJEwJk6qhhMmJSS1YpSJhGw1HCXu76qJ8RQRHR0e5wz09AXsi5tgiMi9QwmSq\n6EoCLUwvH6wjYdtFLYo5Vk9EUdox91bAXn44JWBGwmQeoIRJaWzqIXWeGsZpqxiihPURH4uvE8vY\nigo4b2GOu+XIvEAJk0Lk1chmCdjucLMbLM6dOzc20shbNNPVEUVTEXZyho2G47USUiWUMClE2U0K\nVsReOiKKOG6+iALu9/uZEvYW51JCts/nohyZNyhhMjFedJzKCXvpiJgTBpBZv6tL1IqWpdkmPfr1\nKWMyT1DC5MSktvUWrY4Afp7r9SJgXaqWygmnhGxrgr37hFQJJUwKUaZvglcZYfPAe3t7OH/+PPr9\nPhYXF0fTl+OhJzLrQ7emzJuirGfIpQ5CqoYSJoWwFRBFbu0cuLhFud/v4+joaPR6+/v7I+nm3S4v\nL+MZz3gGbr/9dtx22224ePEilpeXR0KObSopWlIXKGFyYjwB21aT3W53VAER0wvxeVGyRY6lpSWs\nrKyMJKybt8eo2DZsZxRM5hlKmEyMVyMcb3Uqot1ujySqBRxTBvFnsURNn9vbpaUlXLx4cRQF2zly\nMRJOSdhePyFVQwmTQhTdoKEjXN3zN0bA8Xk6VaHFm3d0Op2ReC9cuDAm4ZiOSEXC9jzeJ6RKKGFS\niDIbNWxOuN1uH0tB2ChZb1H2Jm/E83a7PRrmqQ+djtA54XhN+taeE1IllDCZCK8czZsD12q1XAHH\nCHl/f3+sWY/XwEcfrVZrVBkR58rpSolUJKxvCZknKGEyMZ6IIzraTQm40+ng4ODAbVtpxyLF+zF6\ntnPj9CQNb5Iyo2Eyr1DCpBCpOuEoMvuzKNz4HF0tYRfhUs3cvftR4npckTe+KCXh1H1CqoISJlPB\nSi1KWAvYSzPoScup8Ub6sbyeEXZ+XN51ElI1lDApxCQNfKIQvVFFVrbe+3jnXr2v1yOYtcCkLlDC\npBBlhUYBElKMc/lPIYQQMisoYUIIqRBKmBBCKoQSJoSQCqGECSGkQkpJWETeLiKPicgNEbkuIp8Q\nkReY53xIRI7M8ch0L5sQQppB2Uj4HgDvB/BSAK8A0ALwORFZMs/7DIBLAO4YHmsnvE5CCGkkpeqE\nQwiv0vdF5A0A/hnAKoBH1Y/2Qgg/OfHVEUJIwzlpTvh2AAHA0+bxe4fpim+KyEMi8swTvg8hhDSS\niXfMyWBL1PsAPBpC+Ib60WcAfBzAEwB+EcAfAHhERO4OZfe+EkJIwznJtuWHALwQwMv0gyGEh9Xd\nr4vIVwF8B8C9AL54gvcjhJDGMZGEReQDAF4F4J4Qwo+znhtCeEJEfgrgTmRIeH19HSsrK2OPra2t\nYW2Na3qEkPllY2MDGxsbY49tbW0V/n2ZoDvWBwC8GsDLQwj/VOD5zwHwPQCvDiF82vn5ZQDXrl27\nhsuXL5e6FkIImUc2NzexuroKAKshhM2s55atE34IwGsB/DaAbRG5NDy6w58vi8i7ReSlIvJcEbkP\nwJ8B+BaAq5N8GEIIaTJlqyPeBOA2AH8B4El1vGb480MAvwLgkwD+EcD/AvC3AH4thHAwheslhJBG\nUbZOOFPaIYQegF8/0RURQsgZgr0jCCGkQihhQgipEEqYEEIqhBImhJAKoYQJIaRCKGFCCKkQSpgQ\nQiqEEiaEkAqhhAkhpEIoYUIIqRBKmBBCKoQSJoSQCqGECSGkQihhQgipEEqYEEIqhBImhJAKmWsJ\n2+F5TaLJnw1o9ufjZ6sv8/j5KOGKaPJnA5r9+fjZ6ss8fr65ljAhhDQdSpgQQiqEEiaEkAopNW15\nRnQB4PHHHz/2g62tLWxubp76BZ0GTf5sQLM/Hz9bfTmtz6d81s17roQQZns1eRcg8tsA/rTSiyCE\nkNnw2hDCx7KeMA8SfhaAVwL4LoBepRdDCCHToQvgFwBcDSH8LOuJlUuYEELOMlyYI4SQCqGECSGk\nQihhQgipEEqYEEIqZC4lLCK/KyJPiMiuiHxJRP5t1dc0DUTkARE5Msc3qr6uSRCRe0TkUyLyo+Hn\nuN95zjtF5EkR2RGRz4vInVVc6yTkfT4R+ZDzXT5S1fUWRUTeLiKPicgNEbkuIp8QkRc4z6vld1fk\n883bdzd3EhaR3wLwXgAPAPg3AP4ewFUReXalFzY9vgbgEoA7hsevVns5E7MM4CsA3gzgWImNiLwN\nwFsAvBHASwBsY/A9tk/zIk9A5ucb8hmMf5drp3NpJ+IeAO8H8FIArwDQAvA5EVmKT6j5d5f7+YbM\nz3cXQpirA8CXAPx3dV8A/BDA71d9bVP4bA8A2Kz6OmbwuY4A3G8eexLAurp/G4BdAK+p+nqn9Pk+\nBOD/VH1tU/hszx5+vl9t6Hfnfb65+u7mKhIWkRaAVQBfiI+Fwf9qfw7g7qqua8r80vCfuN8RkY+K\nyL+u+oKmjYg8D4PoQn+PNwB8Gc35HgHg3uE/eb8pIg+JyDOrvqAJuB2DSP9poJHf3djnU8zNdzdX\nEsbg/7UWAFw3j1/H4A+j7nwJwBsw2CH4JgDPA/BXIrJc5UXNgDsw+MNv6vcIDP45+3oA/xHA7wN4\nOYBHREQqvaoSDK/1fQAeDSHEtYnGfHeJzwfM2Xc3Dw18zgwhhKvq7tdE5DEA3wPwGgz+iURqQgjh\nYXX36yLyVQDfAXAvgC9WclHleQjACwG8rOoLmRHu55u3727eIuGfAjjEIGGuuQTgqdO/nNkSQtgC\n8C0AtVh5LsFTGOTyz8T3CAAhhCcw+PutxXcpIh8A8CoA94YQfqx+1IjvLuPzHaPq726uJBxCOABw\nDcB98bHhPxHuA/D/qrquWSEiFzD44jP/SOrG8I/6KYx/j7dhsGLduO8RAETkOQCehRp8l0NBvRrA\nfwghfF//rAnfXdbnSzy/0u9uHtMRfwTgwyJyDcBjANYBnAfw4SovahqIyHsA/F8MUhD/CsB/A3AA\nYP4GX+UwzGPfiUHUBADPF5EXAXg6hPADDHJx7xCRb2PQIe9dGFS5fLKCyy1N1ucbHg8A+DgGwroT\nwB9i8K+aq8dfbX4QkYcwKMe6H8C2iMSIdyuEELsY1va7y/t8w+91vr67qsszEmUlb8bgy98F8DcA\nXlz1NU3pc21g8Me8C+D7AD4G4HlVX9eEn+XlGJT+HJrjf6vnPIhBudMOBn/gd1Z93dP4fBi0Kfws\nBv8R9wD8E4D/CeBfVH3dBT6X95kOAbzePK+W313e55vH746tLAkhpELmKidMCCFnDUqYEEIqhBIm\nhJAKoYQJIaRCKGFCCKkQSpgQQiqEEiaEkAqhhAkhpEIoYUIIqRBKmBBCKoQSJoSQCqGECSGkQv4/\nV3bCkkAGMmAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefad20fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = 903\n",
    "plt.imshow(train_set[0][img_id].reshape(28,28),cmap='Greys')\n",
    "print(\"label: \" + str(train_set[1][img_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Donner les caractéristiques de la base d'apprentissage train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDimDataset(train_set):\n",
    "    x= train_set[0]\n",
    "    y=train_set[1]\n",
    "    n_training = x.shape[0]\n",
    "    n_feature = x.shape[1]\n",
    "    n_label = len (set(y))\n",
    "    return n_training, n_feature,n_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDimDataset(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, 10)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDimDataset (train_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init(n_feature,n_label):\n",
    "    sigma = 1.\n",
    "    W = np.random.normal(loc=0.0, scale=sigma/np.sqrt(n_feature), size=(n_label,n_feature))\n",
    "    b = np.zeros((W.shape[0],1))\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W, b = init(n_feature,n_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Donner les dimensions de W et b ainsi que le nombre total de paramètres du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printInfo(W,b):\n",
    "    print(\"W dimensions: \" + str(W.shape))\n",
    "    print(\"b dimensions: \" + str(b.shape))\n",
    "    print(\"Number of parameters: \" + str(W.shape[0]*W.shape[1]+b.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W dimensions: (10, 784)\n",
      "b dimensions: (10, 1)\n",
      "Number of parameters: 7850\n"
     ]
    }
   ],
   "source": [
    "printInfo(W,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Implémenter la fonction forward $$z_j = \\sum_{i \\rightarrow j} W_{ij} x_i + b_j$$ où $x_i$ est un pixel de l'image, $W_{ij}$ est la valeur associée à l'arête reliant les unités $i$ et $j$ et $b_j$ est le bias associé à l'unité $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# f.shape doit retourner 50000 1 \n",
    "def forward(W,b,X):\n",
    "    \"\"\"\n",
    "        Perform the forward propagation\n",
    "        :param W: the weights\n",
    "        :param b: the bias\n",
    "        :param X: the input (minibatch_size x n_input)\n",
    "        :type W: ndarray\n",
    "        :type B: ndarray\n",
    "        :type X: ndarray\n",
    "        :return: the transformed values\n",
    "        :rtype: ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    return (np.dot(W,X.T)+b)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.37754471 -0.19285408 -0.29513715 ..., -0.03102875 -0.41734949\n",
      "   0.22294296]\n",
      " [-0.22547568 -0.30405055 -0.23402171 ...,  0.26355006 -0.31274543\n",
      "  -0.1542858 ]\n",
      " [-0.41019565 -0.41398722 -0.34102203 ..., -1.08010685 -0.34459885\n",
      "  -0.55892953]\n",
      " ..., \n",
      " [ 0.67259055  0.47676633 -0.2124642  ...,  0.31968502 -0.0467562\n",
      "   0.1326427 ]\n",
      " [-0.29405538 -0.45229155 -0.33067278 ..., -0.74254314 -0.1205043\n",
      "  -0.52249787]\n",
      " [ 0.09394785 -0.13875323 -0.092548   ..., -0.00325178  0.05663755\n",
      "  -0.10972443]]\n"
     ]
    }
   ],
   "source": [
    "x= train_set[0]\n",
    "f= forward(W,b,x)\n",
    "#print (f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Implémenter la fonction softmax $$ \\sigma_i = P(t=i|x,W,b) = \\frac{\\exp{z_i}}{\\sum_k \\exp{z_k}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "        Perform the softmax transformation to the pre-activation values\n",
    "        :param z: the pre-activation values\n",
    "        :type z: ndarray\n",
    "        :return: the activation values\n",
    "        :rtype: ndarray\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    e_x = np.exp(z - np.max(z))\n",
    "    return e_x/ e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionnel: Vérifier que votre implémentation de softmax soit numériquement stable (cf. http://ufldl.stanford.edu/wiki/index.php/Exercise:Softmax_Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Example for testing the numerical stability of softmax\n",
    "# It should return [1., 0. ,0.], not [nan, 0., 0.]\n",
    "z = [1000000,1,100]\n",
    "print(softmax(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Implémenter le calcul du gradient de l'erreur par rapport à $z_i$:\n",
    "$$\\delta z_i = \\sigma_i - 1_{i=l}$$\n",
    "où $l$ est l'étiquette associée à la donnée courante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_out(out, one_hot_batch):\n",
    "    \"\"\"\n",
    "    compute the gradient w.r.t. the pre-activation values of the softmax z_i\n",
    "    :param out: the softmax values\n",
    "    :type out: ndarray\n",
    "    :param one_hot_batch: the one-hot representation of the labels\n",
    "    :type one_hot_batch: ndarray\n",
    "    :return: the gradient w.r.t. z\n",
    "    :rtype: ndarray\n",
    "    \"\"\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6: Implémenter la fonction du calcul de gradient par rapport aux paramètres: $$\\delta W_{ij} = \\delta z_j x_i$$  $$\\delta b_{j} = \\delta z_j$$ où $\\delta W_{ij}$ est la composante du gradient associée à l'arête reliant les unités $i$ et $j$, $\\delta b_{j}$ est la composante du gradient associée au bias de l'unité $j$, $\\delta z_j$ est le gradient de l'erreur par rapport à l'unité $j$ et $x_i$ est la valeur d'activation de l'unité $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(derror, X):\n",
    "    \"\"\"\n",
    "        Compute the gradient w.r.t. the parameters\n",
    "        :param derror: the gradient w.r.t. z\n",
    "        :param X: the input (minibatch_size x n_input)\n",
    "        :param minibatch_size: the minibatch size\n",
    "        :type derror: ndarray\n",
    "        :type minibatch: ndarray\n",
    "        :type minibatch_size: unsigned\n",
    "        :return: the gradient w.r.t. the parameters\n",
    "        :rtype: ndarray, ndarray\n",
    "    \"\"\"\n",
    "    grad_w = np.zeros((derror.shape[0],X.shape[1]))\n",
    "    grad_b = np.zeros((derror.shape[0]))\n",
    "    return grad_w,grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: Implémenter la fonction de mise à jour des paramètres $$p = p - \\eta \\delta p$$ où $p$ est un paramètre du modèle et $\\delta p$ la composante du gradient associée à p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(eta, W, b, grad_w, grad_b):\n",
    "    \"\"\"\n",
    "        Update the parameters with an update rule\n",
    "        :param eta: the step-size\n",
    "        :param W: the weights\n",
    "        :param b: the bias\n",
    "        :param grad_w: the gradient w.r.t. the weights\n",
    "        :param grad_b: the gradient w.r.t. the bias\n",
    "        :type eta: float\n",
    "        :type W: ndarray\n",
    "        :type b: ndarray\n",
    "        :type grad_w: ndarray\n",
    "        :type grad_b: ndarray\n",
    "        :return: the updated parameters\n",
    "        :rtype: ndarray, ndarray\n",
    "    \"\"\"\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math,time\n",
    "from IPython.display import clear_output\n",
    "from aux import *\n",
    "\n",
    "# Data structures for plotting\n",
    "g_i = []\n",
    "g_train_loss=[]\n",
    "g_train_acc=[]\n",
    "g_valid_loss=[]\n",
    "g_valid_acc=[]\n",
    "\n",
    "n_training, n_feature, n_label = getDimDataset(train_set)\n",
    "\n",
    "# SGD parameters\n",
    "eta = 0.001\n",
    "batch_size = 500\n",
    "n_batch = int(math.ceil(float(n_training)/batch_size))\n",
    "n_epoch = 100\n",
    "\n",
    "cumul_time = 0.\n",
    "\n",
    "# Initialize the model parameters\n",
    "W,b = init(n_feature,n_label)\n",
    "printInfo(W,b)\n",
    "\n",
    "# Convert the labels to one-hot vector\n",
    "one_hot = np.zeros((n_label,n_training))\n",
    "one_hot[train_set[1],np.arange(n_training)]=1.\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    for j in range(n_batch):\n",
    "\n",
    "        ### Mini-batch creation\n",
    "        minibatch, one_hot_batch, minibatch_size = getMiniBatch(j, batch_size, train_set, one_hot)\n",
    "\n",
    "        prev_time = time.clock()\n",
    "\n",
    "        ### Forward propagation\n",
    "        Z = forward(W,b,minibatch)\n",
    "\n",
    "        ### Compute the softmax\n",
    "        out = softmax(Z)\n",
    "\n",
    "        ### Compute the gradient at the top layer\n",
    "        derror = gradient_out(out,one_hot_batch)\n",
    "\n",
    "        ### Compute the gradient w.r.t. parameters\n",
    "        grad_w,grad_b = gradient(derror, minibatch)\n",
    "\n",
    "        ### Update the parameters\n",
    "        W,b = update(eta, W, b, grad_w, grad_b)\n",
    "        \n",
    "        curr_time = time.clock()\n",
    "        cumul_time += curr_time - prev_time\n",
    "    \n",
    "    ### Training accuracy\n",
    "    train_loss, train_acc = computeLoss(W, b, train_set[0], train_set[1],softmax) \n",
    "    \n",
    "    ### Valid accuracy\n",
    "    valid_loss, valid_acc = computeLoss(W, b, valid_set[0], valid_set[1],softmax) \n",
    "\n",
    "    g_i = np.append(g_i, i)\n",
    "    g_train_loss = np.append(g_train_loss, train_loss)\n",
    "    g_train_acc = np.append(g_train_acc, train_acc)\n",
    "    g_valid_loss = np.append(g_valid_loss, valid_loss)\n",
    "    g_valid_acc = np.append(g_valid_acc, valid_acc)\n",
    "    \n",
    "    result_line = str(i) + \" \" + str(cumul_time) + \" \" + str(train_loss) + \" \" + str(train_acc) + \" \" + str(valid_loss) + \" \" + str(valid_acc) + \" \" + str(eta)\n",
    "    print(result_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(g_i,g_train_loss,label='train_loss')\n",
    "plt.plot(g_i,g_valid_loss,label='valid_loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Negative log-likelihood\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(g_i,1.0-g_train_acc,label='train_acc')\n",
    "plt.plot(g_i,1.0-g_valid_acc,label='valid_acc')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Classification error\")\n",
    "plt.ylim([0.,1.])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8: Montrer, à l'aide d'une figure, l'effet du step-size (prendre $\\eta$=[0.01,0.1,1.0,10.]) sur les courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
