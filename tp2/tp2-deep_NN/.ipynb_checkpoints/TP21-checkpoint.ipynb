{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 : MiniNN Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 décembre 2016  \n",
    "Adapté du TP de Gaétan Marceau-Caron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Au cours du TP1, nous avons étudié le modèle _Softmax_ (aussi connu sous le nom de MaxEnt) pour traiter le problème de classification probabiliste.\n",
    "Le but était de présenter deux étapes importantes de l'entraînement: la {\\it forward propagation} et la mise à jour des paramètres.\n",
    "Le TP2 reprend le modèle Softmax dans un cadre plus général, celui des réseaux de neurones avec couches cachées.\n",
    "\n",
    "Dans ce cadre, on peut considérer le modèle Softmax comme un \"module\" qui prend en entrée des \"features\", e.g. les pixels d'une image, et qui donne en sortie une loi de probabilité sur les étiquettes.\n",
    "D'un point de vue computationnel, un réseau de neurones est composé de plusieurs modules, transformant simplement les features d'un espace à un autre en fonction des valeurs courantes des paramètres.\n",
    "Ainsi, le but de l'entraînement est d'apprendre les transformations pertinentes, i.e., en modifiant les paramètres, qui permettront de réaliser la tâche associée au module de sortie. \n",
    "En augmentant le nombre de modules (mais aussi de fonctions non-linéaires), on augmente ainsi la complexité du modèle.\n",
    "La thèse du {\\it Deep Learning} nous dit que les modules près des données d'entrée doivent apprennent des features de bas niveau, e.g., filtre de Gabor pour l'image, alors que les modules près de la sortie apprennent des features de haut niveau, e.g., la probabilité qu'il y ait un chat dans l'image.\n",
    "A priori, cette hiéarchie des features n'est pas imposée par le programmeur, mais apparaît naturellement lors de l'entraînement avec l'algorithme de backpropagation .\n",
    "\n",
    "Le but du TP2 est de programmer les trois étapes essentielles à l'entraînement d'un réseau de neurones: la forward propagation, la backpropagation et la mise à jour des paramètres.\n",
    "Ensuite, vous pouvez créer un test permettant de vérifier l'implémentation: le test des différences finies.\n",
    "Finalement, vous pourrez comparer les performances de votre réseau de neurones avec celles de votre modèle Softmax de la semaine dernière."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs : \n",
    "    1. Télécharger le TP2\n",
    "    2. Implementer la fonction forward (nn ops.py:72)\n",
    "    3. Implementer la fonction sigmoid et sa d ́eriv ́ee (nn ops.py:149)\n",
    "    4. Implementer la fonction backward (nn ops.py:93)\n",
    "    5. Implementer la fonction update (nn ops.py:123)\n",
    "    6. Entrainer miniNN et obtenir une accuracy meilleur que le modèle softmax (de 0.92)\n",
    "\n",
    "\n",
    "Et optionellemnt : \n",
    "    7. Implementer le test des diff ́erences finies (fd test.py)\n",
    "    \n",
    "La différence finie est une approximation de la dérivée partielle:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial l(w)}{\\partial w_{i}} \\approx \\frac{l(w + \\epsilon e_{i}) - l(w - \\epsilon e_{i})}{2 \\epsilon}\n",
    "\\end{equation}\n",
    "où $l$ est une fonction à plusieurs variables avec ses dérivées partielles définies, $w$ est un vecteur, $w_{i}$ est sa $i$ème composante, $\\epsilon$ est la longeur du pas et $e_{i}$ est le $i$ème vecteur de la base canonique de l'espace euclidien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Livrable\n",
    "\n",
    "- __Date du livrable__: Le 16 décembre 2015  \n",
    "- __Format du livrable__ un fichier compressé nommé \"DL\\_tp2\\_prénom\\_nom.zip\" contenant le code et le résumé   \n",
    "- __Dépôt__ à l'adresse _{thomas.schmitt@inria.fr}_ avec comme objet du message \"DL\\_tp2\\_prénom\\_nom\".  \n",
    "- __Description__  \n",
    "Le livrable associé au TP2 doit contenir le code de MiniNN complété et accompagné d'un résumé de une à deux pages.\n",
    "Le code doit s'exécuter avec la commande _python miniNN.py_ et afficher l'évolution de l'apprentissage (sortie par défaut du programme).  \n",
    "( Ou bien être sous la forme d'un notebook. )\n",
    "\n",
    "Le résumé doit être succinct et se focaliser uniquement sur les points essentiels reliés à l'entraînement des réseaux de neurones.\n",
    "Ce document doit décrire les difficultés que vous avez rencontrées et, dans le cas échéant, les solutions utilisées pour les résoudre.\n",
    "Vous pouvez aussi y décrire vos questions ouvertes et proposer une expérience sur MNIST afin d'y répondre.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zone de Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and minibatch (as in miniNN.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Pour ne pas reload le kernel quand un fichier .py change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy, math, time, sys\n",
    "import dataset_loader\n",
    "from nn_ops import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Retrieve the arguments \n",
    "args = parseArgs_ipython(arch = [400.400], act_func = \"reLU\", batch_size = 500, eta = 0.1, n_epoch = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fix the seed for the random generator\n",
    "np.random.seed(seed=0)\n",
    "\n",
    "#############################\n",
    "### Dataset Handling\n",
    "#############################\n",
    "\n",
    "### Load the dataset\n",
    "train_set, valid_set, test_set = dataset_loader.load_mnist()\n",
    "\n",
    "### Define the dataset variables\n",
    "n_training = train_set[0].shape[0]\n",
    "n_feature = train_set[0].shape[1]\n",
    "n_label = np.max(train_set[1])+1\n",
    "\n",
    "#############################\n",
    "### Neural Network parameters\n",
    "#############################\n",
    "\n",
    "### Activation function\n",
    "act_func_name = args.act_func\n",
    "\n",
    "### Network Architecture\n",
    "nn_arch = np.array([n_feature] + args.arch + [n_label])\n",
    "\n",
    "### Create the neural network\n",
    "W,B,act_func,nb_params = initNetwork(nn_arch,act_func_name)\n",
    "\n",
    "#############################\n",
    "### Optimization parameters\n",
    "#############################\n",
    "eta = args.eta\n",
    "batch_size = args.batch_size\n",
    "n_batch = int(math.ceil(float(n_training)/batch_size))\n",
    "n_epoch = args.n_epoch \n",
    "#regularization= args.regularization\n",
    "#my_lambda= args.my_lambda\n",
    "#############################\n",
    "### Auxiliary variables\n",
    "#############################\n",
    "cumul_time = 0.\n",
    "\n",
    "# Convert the labels to one-hot vector\n",
    "one_hot = np.zeros((n_label,n_training))\n",
    "one_hot[train_set[1],np.arange(n_training)]=1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Mini-batch creation\n",
    "j = 0\n",
    "batch, one_hot_batch, mini_batch_size = getMiniBatch(j, batch_size, train_set, one_hot)\n",
    "X_bacth = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 784)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape\n",
    "#len(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appel de chaque fonction, avec les valeurs calculé avant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Forward propagation\n",
    "\n",
    "Y,Yp = forward(act_func, W, B, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert Y[0].shape == (n_feature, batch_size)\n",
    "assert Y[-1].shape == (10, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-c773e4f19282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mYp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnn_arch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert Yp[0].shape == (nn_arch[1], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "### Compute the softmax\n",
    "out = softmax(Y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert out.shape == (nn_arch[-1], batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Compute the gradient at the top layer\n",
    "derror = out-one_hot_batch\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "derror = out - one_hot_batch\n",
    "assert derror.shape == (nn_arch[-1], batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Backpropagation\n",
    "gradB = backward(derror, W, Yp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "assert len(gradB) == len(nn_arch)-1\n",
    "for gradw,dim in zip(gradB,nn_arch[1:]):\n",
    "    gradw.shape = (dim,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Update the parameters\n",
    "new_W, new_B = update(eta, batch_size, W, B, gradB, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Training accuracy\n",
    "train_loss, train_accuracy = computeLoss(W, B, train_set[0], train_set[1], act_func) \n",
    "\n",
    "### Valid accuracy\n",
    "valid_loss, valid_accuracy = computeLoss(W, B, valid_set[0], valid_set[1], act_func) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22.811062 1.94320841471 0.41342 1.9368533066 0.4248 0.1\n",
      "1 49.366172 1.31921466215 0.6388 1.29460356209 0.6658 0.1\n",
      "2 72.774617 1.01776336847 0.71918 0.979325895557 0.7375 0.1\n",
      "3 94.529341 0.913392265557 0.74462 0.872284676248 0.7646 0.1\n",
      "4 117.026019 0.85833879335 0.76356 0.818010852356 0.7846 0.1\n",
      "5 139.215704 0.816411323063 0.7843 0.777531997702 0.8063 0.1\n",
      "6 163.382448 0.783137194264 0.79826 0.745285142804 0.819 0.1\n",
      "7 186.130292 0.758104621367 0.80828 0.72049947721 0.828 0.1\n",
      "8 210.508332 0.737730205161 0.81456 0.700337314765 0.832 0.1\n",
      "9 238.213912 0.722135343238 0.81876 0.68474781697 0.835 0.1\n",
      "10 266.106275 0.710613062015 0.82184 0.673460379022 0.8393 0.1\n",
      "11 293.323472 0.701134071544 0.82268 0.664069440399 0.8404 0.1\n",
      "12 323.41473 0.694689789519 0.82394 0.65741083085 0.8407 0.1\n",
      "13 349.471663 0.687777977044 0.82514 0.6506465748 0.844 0.1\n",
      "14 376.151659 0.68301600762 0.82518 0.645686566616 0.8439 0.1\n",
      "15 401.675171 0.680511574339 0.82442 0.642369839402 0.8424 0.1\n",
      "16 428.165256 0.677242183745 0.825 0.638841338409 0.8436 0.1\n",
      "17 453.771323 0.675420266391 0.8252 0.636349136429 0.844 0.1\n",
      "18 480.54305 0.673782108267 0.82548 0.634164430278 0.8441 0.1\n",
      "19 506.580685 0.673727387432 0.8255 0.633548045342 0.8437 0.1\n",
      "20 533.086641 0.671733072931 0.82592 0.631163000709 0.8437 0.1\n",
      "21 558.49159 0.672635851036 0.82488 0.631422665771 0.8437 0.1\n",
      "22 583.018277 0.673871535525 0.8244 0.632137398764 0.8445 0.1\n",
      "23 611.508515 0.67239841785 0.82444 0.630504814621 0.8449 0.1\n",
      "24 638.907942 0.672426387139 0.82398 0.630429733941 0.845 0.1\n",
      "25 664.073774 0.670500221988 0.82438 0.628428194722 0.844 0.1\n",
      "26 689.057623 0.670065829327 0.82458 0.627756866861 0.8457 0.1\n",
      "27 716.352978 0.669258221229 0.82502 0.626927743727 0.8456 0.1\n",
      "28 740.907794 0.668005269131 0.82594 0.625763127059 0.8466 0.1\n",
      "29 768.285939 0.668790291647 0.82548 0.626265913971 0.8466 0.1\n",
      "30 795.678551 0.665570359499 0.8265 0.623154052893 0.8471 0.1\n",
      "31 821.44944 0.665570013772 0.82592 0.622961770144 0.8471 0.1\n",
      "32 847.567314 0.664174070339 0.8269 0.62164160105 0.8475 0.1\n",
      "33 872.417389 0.664150889301 0.82652 0.621697655728 0.8476 0.1\n",
      "34 899.712292 0.664769194813 0.82658 0.622403670443 0.8478 0.1\n",
      "35 924.718864 0.664691621002 0.82674 0.622286570986 0.8474 0.1\n",
      "36 950.605642 0.664378673649 0.8266 0.622081644853 0.8479 0.1\n",
      "37 975.403677 0.663585550287 0.82698 0.621425939021 0.8488 0.1\n",
      "38 1001.917715 0.664161006311 0.82618 0.621893524056 0.8485 0.1\n",
      "39 1029.617992 0.664236374138 0.8267 0.622222645743 0.849 0.1\n",
      "40 1054.244745 0.663235253467 0.82688 0.621338354072 0.849 0.1\n",
      "41 1081.00698 0.663920963971 0.82634 0.622096147298 0.849 0.1\n",
      "42 1106.622777 0.663398095426 0.82674 0.621803691745 0.8486 0.1\n",
      "43 1131.773698 0.663763528467 0.82678 0.622122474613 0.8486 0.1\n",
      "44 1160.166556 0.664247484336 0.82632 0.622720898941 0.8475 0.1\n",
      "45 1185.885049 0.664603197021 0.82616 0.623075603005 0.8472 0.1\n",
      "46 1213.417872 0.664575925216 0.82596 0.623241175301 0.8472 0.1\n",
      "47 1239.293133 0.664875806402 0.8259 0.623700145745 0.8465 0.1\n",
      "48 1268.603254 0.664617964622 0.82564 0.623368939786 0.8476 0.1\n",
      "49 1298.153833 0.663453946842 0.82604 0.622204846257 0.8473 0.1\n",
      "50 1331.026285 0.662898394633 0.82664 0.621656749485 0.8478 0.1\n",
      "51 1362.342539 0.66265898737 0.82666 0.621414227479 0.8466 0.1\n",
      "52 1394.308877 0.661781012324 0.8272 0.620829089392 0.8481 0.1\n",
      "53 1422.888499 0.661939015022 0.82666 0.620964084187 0.8472 0.1\n",
      "54 1452.020912 0.662448739217 0.82672 0.621375425859 0.847 0.1\n",
      "55 1482.507176 0.662286666957 0.82662 0.62144594303 0.8465 0.1\n",
      "56 1510.000024 0.662000278971 0.82694 0.62128217396 0.8468 0.1\n",
      "57 1537.401212 0.661342869691 0.82716 0.620745546734 0.8471 0.1\n",
      "58 1561.938123 0.661982232505 0.82706 0.621340847469 0.847 0.1\n",
      "59 1586.10595 0.661880370893 0.82702 0.62119341868 0.8471 0.1\n",
      "60 1609.836709 0.661897694003 0.8271 0.621362561758 0.8471 0.1\n",
      "61 1634.45669 0.661589523544 0.82762 0.621028360138 0.8473 0.1\n",
      "62 1658.447483 0.661835895604 0.82722 0.621368341759 0.8467 0.1\n",
      "63 1686.014161 0.661847317179 0.82758 0.621499664089 0.8473 0.1\n",
      "64 1712.338227 0.662173175858 0.82756 0.621687187765 0.8474 0.1\n",
      "65 1747.12721 0.66269632425 0.8275 0.622286861856 0.8472 0.1\n",
      "66 1772.803178 0.661930850725 0.82814 0.621616685405 0.8474 0.1\n",
      "67 1797.072751 0.662273038897 0.82814 0.621886080054 0.8467 0.1\n",
      "68 1820.241923 0.661789901954 0.82812 0.621691458915 0.8468 0.1\n",
      "69 1845.307657 0.662252108219 0.82838 0.621863792246 0.8466 0.1\n",
      "70 1868.670271 0.662016692445 0.82848 0.621872965007 0.8475 0.1\n",
      "71 1892.368854 0.662622744267 0.82824 0.62234823593 0.8476 0.1\n",
      "72 1916.270337 0.662452611437 0.82804 0.622235900445 0.8462 0.1\n",
      "73 1943.148748 0.662626884452 0.82888 0.622433393794 0.8473 0.1\n",
      "74 1969.75301 0.662194000064 0.82874 0.62205977817 0.8478 0.1\n",
      "75 1993.641912 0.662351483788 0.82882 0.622132744655 0.8475 0.1\n",
      "76 2017.952193 0.662803869746 0.82862 0.622719280804 0.8475 0.1\n",
      "77 2041.798832 0.66274152476 0.82866 0.622623554112 0.847 0.1\n",
      "78 2065.048739 0.662483730827 0.8288 0.622358961838 0.8464 0.1\n",
      "79 2089.85392 0.662295154009 0.82856 0.6221636215 0.8474 0.1\n",
      "80 2113.538358 0.663235531631 0.82776 0.62316393204 0.8466 0.1\n",
      "81 2137.054458 0.661770606964 0.82892 0.621892017227 0.8468 0.1\n",
      "82 2160.929021 0.662575396115 0.8287 0.622583254434 0.8471 0.1\n",
      "83 2184.747912 0.661675503332 0.82906 0.621842189756 0.8475 0.1\n",
      "84 2208.804295 0.661824765253 0.82898 0.622016329004 0.847 0.1\n",
      "85 2232.65544 0.662369972397 0.82858 0.622631029969 0.847 0.1\n",
      "86 2256.851784 0.662168281188 0.82828 0.622380819735 0.8469 0.1\n",
      "87 2282.607398 0.661882920848 0.8289 0.622245169674 0.8467 0.1\n",
      "88 2308.210556 0.662465226321 0.82868 0.62278483185 0.8473 0.1\n",
      "89 2331.965395 0.662313766517 0.82864 0.622620335844 0.8465 0.1\n",
      "90 2356.635869 0.661086911745 0.82926 0.621663449671 0.8478 0.1\n",
      "91 2380.565683 0.661820587461 0.8289 0.622273186846 0.8471 0.1\n",
      "92 2404.346093 0.66153753204 0.82874 0.622229526322 0.8467 0.1\n",
      "93 2427.767697 0.661419710604 0.82912 0.621835309753 0.8472 0.1\n",
      "94 2453.364894 0.661320682658 0.82888 0.621939513922 0.8466 0.1\n",
      "95 2478.311356 0.661406993804 0.82882 0.622105598587 0.8467 0.1\n",
      "96 2507.15433 0.66132585331 0.82888 0.622006044788 0.847 0.1\n",
      "97 2531.410198 0.661685681731 0.82912 0.622459480342 0.8465 0.1\n",
      "98 2557.56595 0.661557565953 0.82898 0.622371964676 0.8464 0.1\n",
      "99 2580.881191 0.661250231976 0.82902 0.622022165377 0.8471 0.1\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "g_train_acc = []\n",
    "g_valid_acc = []\n",
    "for i in range(n_epoch):\n",
    "    for j in range(n_batch):\n",
    "\n",
    "        ### Mini-batch creation\n",
    "        batch, one_hot_batch, mini_batch_size = getMiniBatch(j, batch_size, train_set, one_hot)\n",
    "\n",
    "        prev_time = time.clock()\n",
    "\n",
    "        ### Forward propagation\n",
    "        Y,Yp = forward(act_func, W, B, batch)\n",
    "\n",
    "        ### Compute the softmax\n",
    "        out = softmax(Y[-1])\n",
    "        \n",
    "        ### Compute the gradient at the top layer\n",
    "        derror = out-one_hot_batch\n",
    "\n",
    "        ### Backpropagation\n",
    "        gradB = backward(derror, W, Yp)\n",
    "\n",
    "        ### Update the parameters\n",
    "        W, B = update(eta, batch_size, W, B, gradB, Y)\n",
    "\n",
    "        curr_time = time.clock()\n",
    "        cumul_time += curr_time - prev_time\n",
    "\n",
    "    ### Training accuracy\n",
    "    train_loss, train_accuracy = computeLoss(W, B, train_set[0], train_set[1], act_func) \n",
    "\n",
    "    ### Valid accuracy\n",
    "    valid_loss, valid_accuracy = computeLoss(W, B, valid_set[0], valid_set[1], act_func) \n",
    "\n",
    "    result_line = str(i) + \" \" + str(cumul_time) + \" \" + str(train_loss) + \" \" + str(train_accuracy) + \" \" + str(valid_loss) + \" \" + str(valid_accuracy) + \" \" + str(eta)\n",
    "\n",
    "    #g_i = np.append(g_i, i)\n",
    "    #g_train_loss = np.append(g_train_loss, train_loss)\n",
    "    g_train_acc = np.append(g_train_acc, train_accuracy)\n",
    "    #g_valid_loss = np.append(g_valid_loss, valid_loss)\n",
    "    g_valid_acc = np.append(g_valid_acc, valid_accuracy)\n",
    "    print(result_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fae4dcf3590>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGHCAYAAACNjTnqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKJnJHEgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae4ddf9450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(g_train_acc,label='train_acc')\n",
    "plt.plot(g_valid_acc,label='valid_acc')\n",
    "plt.title(\"accuracy RELU l1 0.01\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accurancy\")\n",
    "plt.ylim([0.,1.])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
